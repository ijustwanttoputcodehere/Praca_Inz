{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scotch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1O_Wu-sMrLblHVlxIbVSdHEKWvyOmdjzm",
      "authorship_tag": "ABX9TyPAMhbPVSPz2SI5j3w6NamH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ijustwanttoputcodehere/Praca_Inz/blob/main/Scotch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBCB_0SLAWMp"
      },
      "source": [
        "Importuję potrzebne biblioteki."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFhjG_JoNjSw"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48C9Qm_4AYc0"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/WhiskyDB/scotch_review.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "MRLNRzOTAmBH",
        "outputId": "f782c31d-9643-442e-af5a-86c0aead59cc"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>name</th>\n",
              "      <th>category</th>\n",
              "      <th>review.point</th>\n",
              "      <th>price</th>\n",
              "      <th>currency</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Johnnie Walker Blue Label, 40%</td>\n",
              "      <td>Blended Scotch Whisky</td>\n",
              "      <td>97</td>\n",
              "      <td>225</td>\n",
              "      <td>$</td>\n",
              "      <td>Magnificently powerful and intense. Caramels, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Black Bowmore, 1964 vintage, 42 year old, 40.5%</td>\n",
              "      <td>Single Malt Scotch</td>\n",
              "      <td>97</td>\n",
              "      <td>4500.00</td>\n",
              "      <td>$</td>\n",
              "      <td>What impresses me most is how this whisky evol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Bowmore 46 year old (distilled 1964), 42.9%</td>\n",
              "      <td>Single Malt Scotch</td>\n",
              "      <td>97</td>\n",
              "      <td>13500.00</td>\n",
              "      <td>$</td>\n",
              "      <td>There have been some legendary Bowmores from t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Compass Box The General, 53.4%</td>\n",
              "      <td>Blended Malt Scotch Whisky</td>\n",
              "      <td>96</td>\n",
              "      <td>325</td>\n",
              "      <td>$</td>\n",
              "      <td>With a name inspired by a 1926 Buster Keaton m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Chivas Regal Ultis, 40%</td>\n",
              "      <td>Blended Malt Scotch Whisky</td>\n",
              "      <td>96</td>\n",
              "      <td>160</td>\n",
              "      <td>$</td>\n",
              "      <td>Captivating, enticing, and wonderfully charmin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2242</th>\n",
              "      <td>2243</td>\n",
              "      <td>Duncan Taylor (distilled at Cameronbridge), Ca...</td>\n",
              "      <td>Grain Scotch Whisky</td>\n",
              "      <td>72</td>\n",
              "      <td>125.00</td>\n",
              "      <td>$</td>\n",
              "      <td>Its best attributes are vanilla, toasted cocon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2243</th>\n",
              "      <td>2244</td>\n",
              "      <td>Distillery Select 'Craiglodge' (distilled at L...</td>\n",
              "      <td>Single Malt Scotch</td>\n",
              "      <td>71</td>\n",
              "      <td>60.00</td>\n",
              "      <td>$</td>\n",
              "      <td>Aged in a sherry cask, which adds sweet notes ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2244</th>\n",
              "      <td>2245</td>\n",
              "      <td>Edradour Barolo Finish, 11 year old, 57.1%</td>\n",
              "      <td>Single Malt Scotch</td>\n",
              "      <td>70</td>\n",
              "      <td>80.00</td>\n",
              "      <td>$</td>\n",
              "      <td>Earthy, fleshy notes with brooding grape notes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2245</th>\n",
              "      <td>2246</td>\n",
              "      <td>Highland Park, Cask #7380, 1981 vintage, 25 ye...</td>\n",
              "      <td>Single Malt Scotch</td>\n",
              "      <td>70</td>\n",
              "      <td>225.00</td>\n",
              "      <td>$</td>\n",
              "      <td>The sherry is very dominant and cloying, which...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2246</th>\n",
              "      <td>2247</td>\n",
              "      <td>Distillery Select 'Inchmoan' (distilled at Loc...</td>\n",
              "      <td>Single Malt Scotch</td>\n",
              "      <td>63</td>\n",
              "      <td>60.00</td>\n",
              "      <td>$</td>\n",
              "      <td>Fiery peat kiln smoke, tar, and ripe barley on...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2247 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ...                                        description\n",
              "0              1  ...  Magnificently powerful and intense. Caramels, ...\n",
              "1              2  ...  What impresses me most is how this whisky evol...\n",
              "2              3  ...  There have been some legendary Bowmores from t...\n",
              "3              4  ...  With a name inspired by a 1926 Buster Keaton m...\n",
              "4              5  ...  Captivating, enticing, and wonderfully charmin...\n",
              "...          ...  ...                                                ...\n",
              "2242        2243  ...  Its best attributes are vanilla, toasted cocon...\n",
              "2243        2244  ...  Aged in a sherry cask, which adds sweet notes ...\n",
              "2244        2245  ...  Earthy, fleshy notes with brooding grape notes...\n",
              "2245        2246  ...  The sherry is very dominant and cloying, which...\n",
              "2246        2247  ...  Fiery peat kiln smoke, tar, and ripe barley on...\n",
              "\n",
              "[2247 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPTPL8c1D2Q-"
      },
      "source": [
        "Testuję metodę wydobycia cech z wyizolowanej kolumny z opisem tekstowym."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH1SGgPoDg6g"
      },
      "source": [
        "import re\r\n",
        "pom = df.iloc[:,-1:]\r\n",
        "pom_list = pom[\"description\"].tolist() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rilZlnlMWvC"
      },
      "source": [
        "pom_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQNUhIJhMucQ",
        "outputId": "fe57481a-18a4-490a-ce45-207edfb00044"
      },
      "source": [
        "type(pom_list) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdmjJwCkEd1l"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPohr3BYHlnk",
        "outputId": "39c2c16c-9cd9-45ee-b67d-8bb5a273b424"
      },
      "source": [
        "#pom = np.array(pom)\r\n",
        "#array_1d = pom.flatten()\r\n",
        "#array_1d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\"Magnificently powerful and intense. Caramels, dried peats, elegant cigar smoke, seeds scraped from vanilla beans, brand new pencils, peppercorn, coriander seeds, and star anise make for a deeply satisfying nosing experience. Silky caramels, bountiful fruits of ripe peach, stewed apple, orange pith, and pervasive smoke with elements of burnt tobacco. An abiding finish of smoke, dry spices, and banoffee pie sweetness. Close to perfection. Editor's Choice\",\n",
              "       \"What impresses me most is how this whisky evolves; it's incredibly complex. On the nose and palate, this is a thick, viscous, whisky with notes of sticky toffee, earthy oak, fig cake, roasted nuts, fallen fruit, pancake batter, black cherry, ripe peach, dark chocolate-covered espresso bean, polished leather, tobacco, a hint of wild game, and lingering, leafy damp kiln smoke. Flavors continue on the palate long after swallowing. This is what we all hope for (and dream of) in an older whisky!\",\n",
              "       \"There have been some legendary Bowmores from the mid-60s and this is every bit their equal. All of them share a remarkable aroma of tropical fruit, which here moves into hallucinatory intensity: guava, mango, peach, pineapple, grapefruit. There’s a very light touch of peat smoke, more a memory of Islay than the reality. Concentrated; even at low strength the palate is silky, heady, and haunting, and lasts forever in the dry glass. A legend is born. (Eight bottles only for the U.S.) Editor's Choice.\",\n",
              "       ...,\n",
              "       'Earthy, fleshy notes with brooding grape notes and a gamey finish -- the Nebbiolo grape influence is obvious. I enjoy Barolo wine and I enjoy Edradour whisky, but the flavors in this whisky mix like oil and water. (Exclusive to Binny’s Beverage Depot.)',\n",
              "       'The sherry is very dominant and cloying, which is unfortunate. And I’m not crazy about the quality of the sherry (or perhaps even the wood it was aged in). I have great respect for both Highland Park and Binny’s, but this is somewhat disappointing for a Highland Park. Tasted twice, with the same opinion. (Bottled for Binny’s Beverage Depot) \\r\\n',\n",
              "       'Fiery peat kiln smoke, tar, and ripe barley on the nose. Not overly complex, but not a problem either. On the palate, the whisky starts out acceptable enough. But by mid-palate, the whisky turns harsh and unpleasant, with petroleum and vegetal notes that continues through to the finish. (Exclusive to Astor Wines and Spirits.) \\r\\n'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w--WxaL6E4o-"
      },
      "source": [
        "#XY = iter(array_1d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHYA0hBOFT55"
      },
      "source": [
        "#XYZ = list(XYZ)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU8oE_5N0xre"
      },
      "source": [
        "Sprawdzam czy lepiej jest liczyć wystąpienia, czy wystąpienia+ ich waga w w-tekście (tf-idf)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEdWoLrLEnqO"
      },
      "source": [
        "vectorizer = CountVectorizer(stop_words='english',min_df=4)\r\n",
        "\r\n",
        "vectorizer.fit((pom_list))\r\n",
        "\r\n",
        "vectorizer.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EGH3A8-y6LO"
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english',min_df=4)\r\n",
        "\r\n",
        "# Learn vocabulary from sentences. \r\n",
        "vectorizer.fit(pom_list)\r\n",
        "\r\n",
        "# Get vocabularies.\r\n",
        "vectorizer.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDyBvJNbNwIv",
        "outputId": "c4514006-f303-42bc-d5a8-17a667d644c8"
      },
      "source": [
        "vector = vectorizer.transform(pom_list)\r\n",
        "vector_spaces = vector.toarray()\r\n",
        "\r\n",
        "vector_spaces"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsIxqBaBOByd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04969ff-01b2-48c0-e2d8-11679dcde8f6"
      },
      "source": [
        "print(vector_spaces[0][:1000])\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Drw6RBbYyXkG",
        "outputId": "50a6f60d-d160-4130-ad5f-3f543ffda311"
      },
      "source": [
        "vector_spaces.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2247, 2961)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DB9xWL157PhK"
      },
      "source": [
        "Zależnie czy wczytam df[\"price\"] czy df[\"review point\"] będę trenował model do przewidzenia stosunku ceny do oceny.Ciekawe, że o ile jestem w stanie znaleźć korelację z oceną, w przypadku ceny jest to trudniejsze(Sporo obiektów ma bardzo odbiegającą cenę która parząc na stosunek cena/ocena nie jest uzasadniona."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1eLrtQVzC9P"
      },
      "source": [
        "pomy = df[\"price\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9yg5cSKzO7q",
        "outputId": "c3a3b952-d06a-4928-85cf-d1cc9c6c5904"
      },
      "source": [
        "pomy.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2247,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2N5fNIY4Q6r"
      },
      "source": [
        "pomy = df['review.point']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj_4Y7tODnW1"
      },
      "source": [
        "X = np.array(vector_spaces)\r\n",
        "y = np.array(pomy)\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGz58eVYF_Jb",
        "outputId": "864bffd3-25be-43c4-d485-eae28912c0ca"
      },
      "source": [
        "X_train.shape[1:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2961,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BBEdkHCaeYM"
      },
      "source": [
        "Próbuję czymś innym, bo sieć jest nieposłuszna."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob06h0U3adRt",
        "outputId": "92d4d33d-b84b-4863-8a54-fcd564a6043a"
      },
      "source": [
        "from xgboost import XGBRegressor\r\n",
        "\r\n",
        "my_model = XGBRegressor()\r\n",
        "my_model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[15:01:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
              "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
              "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
              "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "             silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-nx_QBZbImk",
        "outputId": "3570b6fe-94c8-486f-e2ad-d260520dc656"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\r\n",
        "\r\n",
        "predictions = my_model.predict(X_test)\r\n",
        "print(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 2.8613416597088035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "No3Q9ku3caEy",
        "outputId": "3a38c32e-8902-4788-ff2f-3c27b1b94dd6"
      },
      "source": [
        "y.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86.70004450378282"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILOAeKtPaz8I"
      },
      "source": [
        "Koniec sgd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVM98B7KU5TY"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "\r\n",
        "model = keras.models.Sequential()\r\n",
        "model.add(keras.layers.Flatten(input_shape=X_train.shape[1:]))\r\n",
        "model.add(keras.layers.Dense(30, activation=\"relu\"))\r\n",
        "model.add(keras.layers.Dense(120, activation=\"relu\"))\r\n",
        "model.add(keras.layers.Dense(240, activation=\"relu\"))\r\n",
        "model.add(keras.layers.Dense(120, activation=\"relu\"))\r\n",
        "model.add(keras.layers.Dense(30, activation=\"relu\"))\r\n",
        "model.add(keras.layers.Dense(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHLQgorDZOfT"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "scaler = MinMaxScaler()\r\n",
        "X_train = scaler.fit_transform(X_train)\r\n",
        "# applying the scaling to the test set that we computed for the training set\r\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW0zCbctYHMU",
        "outputId": "04a641f8-f6b7-401e-b9fd-63a286e0afea"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_k2O0KkQYKkO",
        "outputId": "da72f404-606f-4f9b-e6ca-8fc9dd759ce2"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 85, 111,  80, ...,  90, 665, 153])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uylAG_WnU-O1",
        "outputId": "014b6324-88a0-482c-8e46-3ffd2a1a26cc"
      },
      "source": [
        "model.compile(loss=\"mean_squared_error\", optimizer=\"Adam\",metrics=['mae'])\r\n",
        "history = model.fit(X_train, y_train, epochs=100,\r\n",
        "validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 3.3609 - mae: 1.3791 - val_loss: 14.1692 - val_mae: 2.8583\n",
            "Epoch 2/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0888 - mae: 0.2193 - val_loss: 14.1106 - val_mae: 2.8678\n",
            "Epoch 3/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0400 - mae: 0.1449 - val_loss: 14.0722 - val_mae: 2.8633\n",
            "Epoch 4/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0307 - mae: 0.1181 - val_loss: 14.0086 - val_mae: 2.8531\n",
            "Epoch 5/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0287 - mae: 0.1070 - val_loss: 13.9546 - val_mae: 2.8422\n",
            "Epoch 6/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0239 - mae: 0.0984 - val_loss: 14.1082 - val_mae: 2.8725\n",
            "Epoch 7/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0350 - mae: 0.1408 - val_loss: 13.9692 - val_mae: 2.8452\n",
            "Epoch 8/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0224 - mae: 0.1002 - val_loss: 14.1447 - val_mae: 2.8695\n",
            "Epoch 9/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0441 - mae: 0.1511 - val_loss: 14.0614 - val_mae: 2.8526\n",
            "Epoch 10/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0273 - mae: 0.1165 - val_loss: 13.9712 - val_mae: 2.8455\n",
            "Epoch 11/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0261 - mae: 0.1112 - val_loss: 13.9502 - val_mae: 2.8403\n",
            "Epoch 12/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0405 - mae: 0.1137 - val_loss: 13.8936 - val_mae: 2.8370\n",
            "Epoch 13/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0329 - mae: 0.1107 - val_loss: 14.0827 - val_mae: 2.8543\n",
            "Epoch 14/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0537 - mae: 0.1527 - val_loss: 14.0319 - val_mae: 2.8559\n",
            "Epoch 15/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0472 - mae: 0.1600 - val_loss: 13.9350 - val_mae: 2.8432\n",
            "Epoch 16/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0675 - mae: 0.1869 - val_loss: 14.2338 - val_mae: 2.8861\n",
            "Epoch 17/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0874 - mae: 0.2198 - val_loss: 14.1987 - val_mae: 2.8696\n",
            "Epoch 18/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0619 - mae: 0.1798 - val_loss: 14.3479 - val_mae: 2.9006\n",
            "Epoch 19/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0680 - mae: 0.1796 - val_loss: 14.1244 - val_mae: 2.8542\n",
            "Epoch 20/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0840 - mae: 0.2120 - val_loss: 13.7884 - val_mae: 2.8407\n",
            "Epoch 21/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0848 - mae: 0.2166 - val_loss: 14.2948 - val_mae: 2.8548\n",
            "Epoch 22/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1331 - mae: 0.2724 - val_loss: 14.0810 - val_mae: 2.8641\n",
            "Epoch 23/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0866 - mae: 0.2126 - val_loss: 13.9204 - val_mae: 2.8303\n",
            "Epoch 24/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1288 - mae: 0.2762 - val_loss: 13.9331 - val_mae: 2.8378\n",
            "Epoch 25/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0991 - mae: 0.2471 - val_loss: 14.1793 - val_mae: 2.8829\n",
            "Epoch 26/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.1299 - mae: 0.2766 - val_loss: 14.0201 - val_mae: 2.8556\n",
            "Epoch 27/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0692 - mae: 0.1953 - val_loss: 13.9347 - val_mae: 2.8363\n",
            "Epoch 28/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0751 - mae: 0.2028 - val_loss: 13.9419 - val_mae: 2.8427\n",
            "Epoch 29/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0660 - mae: 0.1723 - val_loss: 13.9177 - val_mae: 2.8480\n",
            "Epoch 30/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1491 - mae: 0.2949 - val_loss: 14.1886 - val_mae: 2.8678\n",
            "Epoch 31/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1347 - mae: 0.2857 - val_loss: 13.9905 - val_mae: 2.8379\n",
            "Epoch 32/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1231 - mae: 0.2569 - val_loss: 14.2180 - val_mae: 2.8697\n",
            "Epoch 33/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0894 - mae: 0.2151 - val_loss: 14.0453 - val_mae: 2.8313\n",
            "Epoch 34/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1380 - mae: 0.2939 - val_loss: 14.1436 - val_mae: 2.8380\n",
            "Epoch 35/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1615 - mae: 0.3251 - val_loss: 14.0734 - val_mae: 2.8678\n",
            "Epoch 36/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1006 - mae: 0.2412 - val_loss: 14.0604 - val_mae: 2.8737\n",
            "Epoch 37/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1255 - mae: 0.2855 - val_loss: 14.2317 - val_mae: 2.8988\n",
            "Epoch 38/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1235 - mae: 0.2727 - val_loss: 13.8932 - val_mae: 2.8381\n",
            "Epoch 39/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0626 - mae: 0.1791 - val_loss: 14.2460 - val_mae: 2.8615\n",
            "Epoch 40/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0764 - mae: 0.2124 - val_loss: 13.8035 - val_mae: 2.8397\n",
            "Epoch 41/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0590 - mae: 0.1843 - val_loss: 14.0900 - val_mae: 2.8519\n",
            "Epoch 42/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0746 - mae: 0.2115 - val_loss: 14.1156 - val_mae: 2.8763\n",
            "Epoch 43/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.2152 - mae: 0.3708 - val_loss: 13.8494 - val_mae: 2.8269\n",
            "Epoch 44/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1891 - mae: 0.3221 - val_loss: 14.6231 - val_mae: 2.9632\n",
            "Epoch 45/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1875 - mae: 0.3514 - val_loss: 13.7507 - val_mae: 2.8230\n",
            "Epoch 46/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0944 - mae: 0.2174 - val_loss: 14.1273 - val_mae: 2.8665\n",
            "Epoch 47/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1198 - mae: 0.2536 - val_loss: 13.9541 - val_mae: 2.8359\n",
            "Epoch 48/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0611 - mae: 0.1681 - val_loss: 14.0672 - val_mae: 2.8573\n",
            "Epoch 49/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0386 - mae: 0.1376 - val_loss: 14.0350 - val_mae: 2.8568\n",
            "Epoch 50/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0418 - mae: 0.1477 - val_loss: 14.2683 - val_mae: 2.8841\n",
            "Epoch 51/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0368 - mae: 0.1401 - val_loss: 13.9041 - val_mae: 2.8398\n",
            "Epoch 52/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0324 - mae: 0.1274 - val_loss: 14.0781 - val_mae: 2.8532\n",
            "Epoch 53/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0900 - mae: 0.2381 - val_loss: 13.9007 - val_mae: 2.8438\n",
            "Epoch 54/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0792 - mae: 0.2147 - val_loss: 14.0436 - val_mae: 2.8605\n",
            "Epoch 55/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0560 - mae: 0.1704 - val_loss: 13.8958 - val_mae: 2.8338\n",
            "Epoch 56/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0504 - mae: 0.1643 - val_loss: 14.0323 - val_mae: 2.8764\n",
            "Epoch 57/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0861 - mae: 0.2183 - val_loss: 14.0407 - val_mae: 2.8379\n",
            "Epoch 58/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0726 - mae: 0.2048 - val_loss: 14.1193 - val_mae: 2.8765\n",
            "Epoch 59/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0500 - mae: 0.1685 - val_loss: 14.0685 - val_mae: 2.8698\n",
            "Epoch 60/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0512 - mae: 0.1685 - val_loss: 14.1237 - val_mae: 2.8794\n",
            "Epoch 61/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0719 - mae: 0.2158 - val_loss: 14.0969 - val_mae: 2.8443\n",
            "Epoch 62/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0871 - mae: 0.2219 - val_loss: 14.0039 - val_mae: 2.8575\n",
            "Epoch 63/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0668 - mae: 0.1860 - val_loss: 14.2922 - val_mae: 2.9078\n",
            "Epoch 64/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1107 - mae: 0.2642 - val_loss: 13.8117 - val_mae: 2.8282\n",
            "Epoch 65/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1764 - mae: 0.3090 - val_loss: 14.1252 - val_mae: 2.8569\n",
            "Epoch 66/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.2148 - mae: 0.3616 - val_loss: 14.2664 - val_mae: 2.8633\n",
            "Epoch 67/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1723 - mae: 0.3114 - val_loss: 13.6892 - val_mae: 2.8034\n",
            "Epoch 68/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1526 - mae: 0.2851 - val_loss: 13.7893 - val_mae: 2.8419\n",
            "Epoch 69/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.1537 - mae: 0.2957 - val_loss: 13.8178 - val_mae: 2.8472\n",
            "Epoch 70/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.2516 - mae: 0.4003 - val_loss: 14.4045 - val_mae: 2.8659\n",
            "Epoch 71/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.5341 - mae: 0.5939 - val_loss: 14.2943 - val_mae: 2.9078\n",
            "Epoch 72/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.2162 - mae: 0.3443 - val_loss: 14.1015 - val_mae: 2.8825\n",
            "Epoch 73/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.2051 - mae: 0.3585 - val_loss: 14.0225 - val_mae: 2.8520\n",
            "Epoch 74/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0826 - mae: 0.2108 - val_loss: 13.8457 - val_mae: 2.8238\n",
            "Epoch 75/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0922 - mae: 0.2320 - val_loss: 13.7229 - val_mae: 2.8129\n",
            "Epoch 76/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0509 - mae: 0.1647 - val_loss: 13.8287 - val_mae: 2.8315\n",
            "Epoch 77/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0249 - mae: 0.1115 - val_loss: 13.7506 - val_mae: 2.8157\n",
            "Epoch 78/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0342 - mae: 0.1335 - val_loss: 14.0355 - val_mae: 2.8661\n",
            "Epoch 79/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0344 - mae: 0.1176 - val_loss: 13.8206 - val_mae: 2.8248\n",
            "Epoch 80/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0236 - mae: 0.0871 - val_loss: 13.9907 - val_mae: 2.8489\n",
            "Epoch 81/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0351 - mae: 0.1279 - val_loss: 13.8495 - val_mae: 2.8213\n",
            "Epoch 82/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0270 - mae: 0.1131 - val_loss: 13.9782 - val_mae: 2.8397\n",
            "Epoch 83/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0332 - mae: 0.1192 - val_loss: 13.9473 - val_mae: 2.8393\n",
            "Epoch 84/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0229 - mae: 0.1007 - val_loss: 13.9008 - val_mae: 2.8399\n",
            "Epoch 85/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0355 - mae: 0.1276 - val_loss: 13.9963 - val_mae: 2.8613\n",
            "Epoch 86/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0434 - mae: 0.1462 - val_loss: 13.7711 - val_mae: 2.8285\n",
            "Epoch 87/100\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.0519 - mae: 0.1598 - val_loss: 13.9201 - val_mae: 2.8522\n",
            "Epoch 88/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0895 - mae: 0.2296 - val_loss: 14.0067 - val_mae: 2.8372\n",
            "Epoch 89/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1283 - mae: 0.2789 - val_loss: 13.9253 - val_mae: 2.8448\n",
            "Epoch 90/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.0838 - mae: 0.2195 - val_loss: 14.0733 - val_mae: 2.8706\n",
            "Epoch 91/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0706 - mae: 0.1998 - val_loss: 13.8636 - val_mae: 2.8407\n",
            "Epoch 92/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1001 - mae: 0.2501 - val_loss: 14.1147 - val_mae: 2.8727\n",
            "Epoch 93/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.0997 - mae: 0.2229 - val_loss: 13.8689 - val_mae: 2.8391\n",
            "Epoch 94/100\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 0.1279 - mae: 0.2725 - val_loss: 13.8124 - val_mae: 2.8477\n",
            "Epoch 95/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1989 - mae: 0.3498 - val_loss: 14.1609 - val_mae: 2.8764\n",
            "Epoch 96/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1990 - mae: 0.3410 - val_loss: 14.3741 - val_mae: 2.9364\n",
            "Epoch 97/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.6591 - mae: 0.6486 - val_loss: 14.0439 - val_mae: 2.8453\n",
            "Epoch 98/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.2675 - mae: 0.3613 - val_loss: 14.1050 - val_mae: 2.8600\n",
            "Epoch 99/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1509 - mae: 0.2914 - val_loss: 14.1359 - val_mae: 2.8484\n",
            "Epoch 100/100\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.1266 - mae: 0.2633 - val_loss: 13.8269 - val_mae: 2.8287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEW3fPYew05X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FC3WNFpptnF"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "vNGejt9mp0J0",
        "outputId": "1911d8af-d666-41be-d836-ca0836f5e027"
      },
      "source": [
        "plt.plot(history.history['mae'], label='train')\r\n",
        "plt.plot(history.history['val_mae'], label='test')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZOrPUUjVgit",
        "outputId": "f23c2aea-f241-4e8e-84ec-1ca394109a45"
      },
      "source": [
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 1ms/step - loss: 173.9520 - mean_squared_error: 173.9520\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d8qP0m6kwSp",
        "outputId": "91cd5d2a-0588-499c-c589-ad7938c523d1"
      },
      "source": [
        "mse_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[173.9520263671875, 173.9520263671875]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzd2qvJ5NQhE"
      },
      "source": [
        "Ponizej robiłem obliczenia z wykluczeniem kolumny tekstowej 'description'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "bJjyUPJXLmZs",
        "outputId": "07ab5970-5fb6-4b8c-c70a-48cbf114f665"
      },
      "source": [
        "df = df.iloc[:,1:]\r\n",
        "df = df.iloc[:,:-2]\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>category</th>\n",
              "      <th>review.point</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Johnnie Walker Blue Label, 40%</td>\n",
              "      <td>Blended Scotch Whisky</td>\n",
              "      <td>97</td>\n",
              "      <td>225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Black Bowmore, 1964 vintage, 42 year old, 40.5%</td>\n",
              "      <td>Single Malt Scotch</td>\n",
              "      <td>97</td>\n",
              "      <td>4500.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bowmore 46 year old (distilled 1964), 42.9%</td>\n",
              "      <td>Single Malt Scotch</td>\n",
              "      <td>97</td>\n",
              "      <td>13500.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Compass Box The General, 53.4%</td>\n",
              "      <td>Blended Malt Scotch Whisky</td>\n",
              "      <td>96</td>\n",
              "      <td>325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Chivas Regal Ultis, 40%</td>\n",
              "      <td>Blended Malt Scotch Whisky</td>\n",
              "      <td>96</td>\n",
              "      <td>160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2242</th>\n",
              "      <td>Duncan Taylor (distilled at Cameronbridge), Ca...</td>\n",
              "      <td>Grain Scotch Whisky</td>\n",
              "      <td>72</td>\n",
              "      <td>125.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2243</th>\n",
              "      <td>Distillery Select 'Craiglodge' (distilled at L...</td>\n",
              "      <td>Single Malt Scotch</td>\n",
              "      <td>71</td>\n",
              "      <td>60.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2244</th>\n",
              "      <td>Edradour Barolo Finish, 11 year old, 57.1%</td>\n",
              "      <td>Single Malt Scotch</td>\n",
              "      <td>70</td>\n",
              "      <td>80.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2245</th>\n",
              "      <td>Highland Park, Cask #7380, 1981 vintage, 25 ye...</td>\n",
              "      <td>Single Malt Scotch</td>\n",
              "      <td>70</td>\n",
              "      <td>225.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2246</th>\n",
              "      <td>Distillery Select 'Inchmoan' (distilled at Loc...</td>\n",
              "      <td>Single Malt Scotch</td>\n",
              "      <td>63</td>\n",
              "      <td>60.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2247 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   name  ...     price\n",
              "0                        Johnnie Walker Blue Label, 40%  ...       225\n",
              "1       Black Bowmore, 1964 vintage, 42 year old, 40.5%  ...   4500.00\n",
              "2           Bowmore 46 year old (distilled 1964), 42.9%  ...  13500.00\n",
              "3                        Compass Box The General, 53.4%  ...       325\n",
              "4                               Chivas Regal Ultis, 40%  ...       160\n",
              "...                                                 ...  ...       ...\n",
              "2242  Duncan Taylor (distilled at Cameronbridge), Ca...  ...    125.00\n",
              "2243  Distillery Select 'Craiglodge' (distilled at L...  ...     60.00\n",
              "2244         Edradour Barolo Finish, 11 year old, 57.1%  ...     80.00\n",
              "2245  Highland Park, Cask #7380, 1981 vintage, 25 ye...  ...    225.00\n",
              "2246  Distillery Select 'Inchmoan' (distilled at Loc...  ...     60.00\n",
              "\n",
              "[2247 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPJwgOsIe-aE",
        "outputId": "3cda96a3-33d5-485a-bc33-93cf00a9cee1"
      },
      "source": [
        "import re\r\n",
        "\r\n",
        "int_price=[]\r\n",
        "\r\n",
        "# finding out the complications in the column\r\n",
        "for i in df['price']:\r\n",
        "    #removing $ and , so that we can convert this feature price into integer type\r\n",
        "    _=re.sub(r'[$,]+','',i)\r\n",
        "    #converting float integrs\r\n",
        "    x=re.sub(r'\\W\\d\\d','',_)\r\n",
        "    z=0\r\n",
        "    #converting liter into one botle price\r\n",
        "    if (\"/l\" in x):\r\n",
        "        l=re.sub(r'[/l]\\w+','',x)\r\n",
        "        \r\n",
        "        z=int(l)\r\n",
        "        z=z*.75\r\n",
        "        int_price.append(z)\r\n",
        "        \r\n",
        "    # if any of the alphanumeric value like space like we encountered the case : ('$15,000 or $60,000/set')     \r\n",
        "    elif(\" \" in  x):\r\n",
        "        l= re.sub(r'[ ]\\w+\\W+\\w+','',x)\r\n",
        "        z=int(l)\r\n",
        "        int_price.append(z)\r\n",
        "            \r\n",
        "    elif (\"set\" in x):\r\n",
        "        l=re.sub(r'[/]\\w+','',x)\r\n",
        "        \r\n",
        "        z= int(l)\r\n",
        "        z=z/4\r\n",
        "        int_price.append(z)\r\n",
        "    else :\r\n",
        "        z=int(x)\r\n",
        "        int_price.append(z)\r\n",
        "print(int_price)     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[225, 4500, 13500, 325, 160, 85, 6250, 11000, 1500, 3360, 750, 1500, 3108, 105, 120, 3500, 70, 20000, 70, 15000, 26650, 400, 200, 400, 455, 750, 200, 460, 2525, 1250, 280, 500, 215, 300, 400, 2000, 4000, 225, 60, 180, 300, 3500, 120, 181, 20000, 800, 250, 500, 6000, 30000, 645, 11824, 1250, 550, 700, 140, 400, 700, 387, 5730, 100, 325, 300, 350, 350, 6088, 3500, 112, 109, 130, 100, 120, 1900, 100, 200, 1400, 84, 3000, 225, 164, 50, 150, 140, 175, 1100, 157000, 850, 34, 600, 225, 55, 60, 600, 400, 250, 15000.0, 90, 191, 1925, 2200, 1700, 430, 1100, 150, 300, 135, 250, 3000, 750, 60000, 95, 262, 750, 599, 9420, 600, 2000, 100, 350, 45, 85, 2850, 500, 1000, 150, 100, 1900, 3657, 127, 167, 1200, 525, 280, 3500, 80, 304, 370, 455, 3300, 4000, 3500, 580, 200, 240, 300, 65, 4500, 4000, 170, 60, 300, 248, 2000, 76, 236, 173, 560, 380, 100, 200, 145, 260, 140, 290, 85, 85, 150, 115, 130, 75, 225, 275, 125, 200, 815, 53, 99, 120, 200, 80, 125, 250, 100, 95, 155, 263, 95, 1600, 1722, 1500, 120, 1100, 95, 1300, 125, 5000, 1230, 7500, 195, 336, 12000, 580, 16000, 383, 135, 600, 4640, 800, 110, 375, 2050, 220, 300, 615, 160, 220, 485, 382, 438, 106, 132, 3700, 300, 90, 624, 152, 60, 250, 166, 150, 148, 220, 250, 52, 1000, 60, 65, 240, 294, 250, 488, 150, 1400, 130, 160, 275, 205, 200, 850, 600, 90, 260, 600, 730, 4000, 75, 250, 70, 60, 1000, 162, 140, 75, 100, 137, 48, 70, 140, 80, 100, 225, 66, 152, 450, 216, 50, 65, 170, 300, 65, 45, 840, 400, 80, 499, 160, 100, 100, 160, 160, 110, 550, 110, 115, 80, 62, 369, 220, 350, 283, 1600, 1735, 160, 85, 100, 140, 350, 330, 1100, 130, 152, 258, 96, 500, 175, 236, 24000, 530, 592, 407, 320, 113, 500, 850, 418, 250, 131, 530, 9500, 750, 250, 395, 150, 85, 1593, 875, 100, 100, 100, 112, 225, 50, 135, 1450, 118, 2750, 65, 200, 2313, 110, 375, 135, 85, 150, 359, 1000, 23427, 150, 488, 4000, 329, 81, 51, 100, 200, 80, 657, 111, 150, 145, 280, 536, 763, 246, 300, 103, 200, 79, 158, 615, 169, 65, 60, 287, 120, 59, 65, 60, 300, 60, 40, 30, 170, 50, 125, 60, 55, 60, 65, 130, 100, 450, 75, 100, 120, 550, 120, 250, 250, 27620, 15000.0, 325, 400, 80, 555, 550, 240, 59, 460, 800, 65, 100, 92, 90, 118, 225, 80, 65, 285, 234, 57, 72, 87, 65, 160, 265, 200, 7500, 133, 700, 85, 125, 59, 8000, 1980, 975, 1215, 512, 289, 177, 125, 71, 900, 540, 270, 379, 99, 2339, 185, 100, 260, 471, 2000, 155, 421, 125, 60, 36, 155, 21000, 1230, 450, 300, 70, 119, 99, 53, 70, 330, 188, 60, 46, 200, 300, 900, 75, 162, 90, 100, 1500, 99, 252, 180, 185, 700, 117, 187, 65, 105, 95, 157, 93, 127, 300, 256, 275, 100, 307, 160, 59, 50, 65, 349, 50, 250, 88, 230, 415, 140, 30, 989, 109, 76, 100, 232, 90, 55, 59, 936, 229, 115, 45, 85, 55, 70, 399, 150, 180, 200, 51, 104, 117, 127, 390, 76, 160, 160, 100, 53, 2020, 698, 422, 190, 295, 587, 900, 130, 246, 50, 108, 43, 453, 1200, 120, 70, 235, 165, 65, 140, 35, 180, 220, 188, 60, 55, 45, 33.0, 32, 33, 160, 110, 100, 130, 85, 90, 151, 191, 500, 78, 130, 108, 120, 130, 120, 100, 70, 550, 55, 3500, 150, 60, 170, 87, 86, 180, 174, 95, 70, 1500, 120, 90, 160, 125, 180, 110, 322, 83, 66, 420, 53, 75, 45, 75, 150, 50, 110, 140, 67, 600, 115, 17600, 3600, 340, 160, 145, 245, 97, 6000, 329, 1052, 130, 120, 99, 110, 100, 100, 98, 1087, 557, 189, 200, 165, 130, 700, 305, 200, 135, 75, 99, 99, 80, 120, 55, 123, 313, 824, 165, 210, 150, 2880, 120, 1348, 560, 300, 63, 85, 108, 118, 5450, 155, 105, 90, 110, 154, 230, 220, 151, 100, 94, 100, 63, 195, 400, 279, 3700, 261, 300, 485, 105, 200, 66, 130, 200, 225, 350, 61, 72, 52, 290, 262, 140, 275, 625, 31, 80, 53, 172, 124, 64, 75, 50, 65, 100, 310, 140, 175, 35, 300, 70, 380, 69, 1150, 45, 69, 74, 190, 120, 181, 83, 130, 255, 140, 100, 100, 114, 46, 168, 718, 130, 100, 68, 549, 100, 57, 7000, 128, 150, 168, 503, 749, 111, 165, 84, 90, 55, 350, 68, 165, 406, 50, 38, 45, 55, 126, 3378, 43, 30, 80, 300, 160, 80, 170, 125, 119, 130, 130, 110, 820, 65, 130, 53, 85, 90, 3982, 599, 99, 140, 195, 50, 100, 160, 50, 610, 75, 130, 385, 100, 120, 65, 101, 230, 66, 99, 50, 85, 225, 170, 60, 205, 79, 100, 165, 126, 800, 815, 80, 200, 156, 229, 2260, 100, 95, 135, 90, 480, 665, 81, 70, 109, 160, 95, 160, 180, 100, 57, 205, 80, 62, 80, 111, 82, 115, 80, 90, 125, 124, 140, 158, 54, 110, 124, 125, 215, 539, 270, 70, 322, 500, 180, 77, 65, 60, 60, 142, 135, 210, 115, 55, 29, 79, 230, 650, 103, 567, 89, 65, 55, 62, 65, 200, 2280, 600, 170, 500, 135, 75, 190, 160, 100, 89, 76, 81, 160, 175, 70, 60, 553, 780, 78, 96, 145, 188, 84, 124, 160, 80, 117, 125, 40, 41, 60, 60, 45, 359, 1400, 101, 200, 65, 37, 80, 139, 190, 297, 75, 127, 49, 70, 294, 65, 220, 91, 150, 108, 40, 676, 113, 61, 140, 85, 265, 100, 105, 200, 422, 141, 636, 40, 115, 262, 548, 62, 63, 25, 55, 70, 180, 45, 65, 65, 70, 13, 43, 267, 80, 135, 48, 62, 199, 99, 65, 30, 300, 160, 55, 110, 105, 110, 50, 62, 66, 130, 75, 80, 607, 750, 145, 375, 65, 60, 6542, 15000.0, 300, 70, 93, 66, 65, 140, 137, 60, 100, 48, 70, 120, 138, 100, 60, 95, 1000, 80, 80, 140, 100, 48, 135, 3104, 55, 70, 156, 167, 120, 45, 70, 100, 68, 65, 50, 150, 69, 72, 300, 81, 85, 135, 80, 50, 406, 52, 98, 138, 14999, 110, 114, 88, 137, 115, 210, 451, 48, 75, 72, 386, 392, 1456, 4664, 111, 62, 86, 95, 108, 637, 80, 200, 50, 200, 70, 58, 56, 78, 322, 60, 140, 215, 78, 48, 250, 270, 71, 40, 100, 500, 325, 108, 82, 135, 2000, 549, 90, 400, 175, 80, 35, 120, 92, 2000, 60, 270, 72, 950, 100, 105, 77, 471, 135, 180, 240, 36, 60, 400, 353, 250, 337, 120, 300, 460, 70, 130, 164, 230, 189, 133, 144, 132, 127, 29, 48, 30, 63, 100, 92, 76, 210, 158, 25, 55, 58, 60, 85, 80, 123, 108, 101, 117, 102, 178, 106, 42, 190, 83, 151, 59, 62, 120, 110, 140, 145, 170, 345, 135, 78, 132, 76, 95, 50, 65, 84, 30, 110, 43, 302, 63, 72, 127, 325, 60, 277, 72, 1750, 288, 65, 65, 33, 116, 62, 35, 805, 58, 25, 110, 130, 80, 80, 70, 125, 123, 1500, 95, 63, 62, 70, 126, 97, 120, 140, 62, 130, 15000.0, 40, 85, 140, 54, 101, 70, 115, 75, 129, 119, 630, 455, 100, 130, 68, 100, 123, 421, 100, 103, 140, 74, 125, 126, 69, 69, 3200, 65, 300, 480, 80, 105, 105, 85, 92, 42, 59, 110, 48, 100, 803, 589, 1279, 37, 78, 62, 500, 55, 125, 170, 175, 694, 625, 50, 70, 75, 450, 98, 125, 125, 86, 135, 80, 956, 140, 84, 60, 410, 653, 175, 180, 96, 69, 202, 235, 140, 70, 48, 35, 119, 130, 125, 160, 70, 135, 125, 2750, 95, 1013, 121, 32, 384, 75, 85, 280, 98, 150, 79, 75, 58, 115, 113, 95, 100, 100, 90, 83, 353, 69, 50, 185, 210, 40, 80, 55, 50, 50, 50, 152, 76, 125, 65, 125, 100, 87, 79, 81, 159, 129, 176, 129, 122, 150, 79, 54, 39, 50, 100, 135, 55, 30, 30, 30, 29, 58, 120, 20, 1250, 45, 165, 85, 135, 80, 38, 100, 115, 179, 78, 52, 65, 90, 62, 60, 180, 169, 92, 110, 224, 144, 105, 124, 80, 150, 180, 100, 175, 67, 110, 101, 45, 78, 25, 199, 25, 59, 47, 763, 43, 120, 115, 119, 168, 32, 29, 54, 45, 48, 30, 33, 159, 40, 26, 80, 25, 225, 65, 80, 63, 95, 150, 70, 60, 53, 60, 101, 100, 100, 130, 83, 90, 130, 1872, 96, 88, 65, 150, 100, 63, 63, 1000, 1500, 180, 74, 100, 130, 37, 250, 239, 88, 265, 70, 56, 215, 50, 70, 70, 134, 53, 150, 69, 6400, 118, 70, 99, 65, 150, 80, 300, 60, 67, 76, 119, 120, 200, 80, 140, 120, 78, 92, 120, 115, 46, 67, 65, 40, 92, 92, 410, 33, 55, 83, 55, 88, 49, 124, 505, 85, 111, 60, 796, 61, 1141, 103, 111, 3000, 78, 135, 135, 135, 60, 80, 110, 115, 900, 72, 165, 207, 3000, 130, 160, 150, 125, 45, 60, 2750, 406, 80, 67, 815, 53, 212, 45, 75, 160, 95, 350, 70, 50, 73, 65, 89, 99, 45, 250, 75, 80, 110, 115, 70, 70, 133, 105, 174, 95, 137, 95, 143, 133, 107, 129, 57, 54, 122, 70, 100, 297, 30, 92, 450, 450, 25, 178, 89, 604, 76, 62, 31, 18, 22, 152, 66, 110, 44, 45, 92, 152, 512, 53, 85, 80, 111, 65, 110, 151, 70, 17, 400, 80, 173, 191, 30, 45, 23, 101, 65, 25, 45, 44, 80, 90, 100, 70, 78, 45, 45, 70, 66, 70, 50, 94, 63, 80, 100, 1008, 85, 450, 54, 81, 101, 400, 125, 80, 53, 90, 100, 125, 78, 274, 71, 75, 75, 90, 65, 50, 60, 85, 325, 153, 101, 108, 100, 45, 65, 65, 58, 100, 90, 135, 50, 145, 127, 56, 74, 58, 130, 136, 724, 123, 70, 140, 78, 72, 68, 65, 70, 92, 99, 45, 60, 65, 180, 120, 68, 151, 110, 500, 60, 80, 65, 246, 282, 140, 320, 75, 70, 952, 50, 150, 68, 95, 150, 185, 100, 48, 110, 54, 220, 40, 50, 40, 81, 152, 87, 50, 150, 75, 70, 1900, 77, 27, 127, 104, 131, 61, 115, 55, 29, 17, 80, 95, 75, 50, 70, 90, 35, 49, 60, 29, 76, 76, 74, 49, 22, 100, 270, 123, 133, 73, 125, 345, 180, 84, 60, 78, 96, 100, 475, 76, 160, 45, 183, 20, 43, 191, 400, 275, 56, 117, 122, 124, 98, 81, 161, 55, 16, 25, 43, 40, 39, 95, 85, 25, 195, 80, 62, 120, 40, 74, 90, 55, 225, 85, 90, 113, 690, 110, 120, 55, 170, 170, 180, 60, 50, 85, 88, 117, 138, 84, 85, 150, 45, 265, 135, 140, 155, 160, 100, 73, 160, 210, 592, 125, 36, 90, 155, 900, 50, 100, 156, 700, 89, 67, 73, 440, 51, 90, 93, 111, 130, 45, 49, 220, 80, 137, 76, 75, 65, 121, 190, 70, 44, 90, 2750, 70, 56, 567, 185, 63, 97, 70, 40, 40, 73, 55, 180, 70, 65, 30, 70, 119, 154, 164, 104, 190, 54, 125, 60, 108, 78, 40, 325, 100, 90, 45, 61, 61, 46, 119, 160, 100, 142, 77, 32, 98, 60, 168, 119, 73, 69, 110, 90, 90, 95, 72, 73, 76, 37, 33, 44, 53, 65, 348, 61, 115, 126, 60, 195, 69, 22, 40, 55, 700, 212, 90, 101, 75, 50, 150, 88, 465, 65, 75, 60, 1250, 135, 100, 72, 55, 32, 180, 90, 65, 125, 65, 56, 288, 55, 72, 84, 44, 90, 150, 65, 60, 151, 73, 73, 70, 115, 100, 59, 52, 48, 59, 100, 65, 120, 124, 53, 65, 200, 80, 100, 100, 30, 200, 100, 42, 50, 70, 65, 70, 70, 40, 40, 55, 30, 55, 58, 52, 157, 91, 64, 18, 15, 67, 130, 56, 101, 88, 191, 100, 206, 35, 73, 135, 50, 25, 17, 145, 40, 126, 185, 200, 45, 33, 145, 35, 80, 160, 153, 140, 65, 65, 135, 84, 109, 210, 93, 115, 175, 45, 60, 899, 109, 60, 238, 63, 55, 80, 70, 138, 80, 75, 25, 133, 90, 125, 170, 135, 300, 155, 67, 75, 52, 40, 112, 53, 78, 82, 61, 60, 239, 80, 21, 134, 340, 14, 12, 53, 75, 155, 146, 108, 56, 117, 82, 98, 109, 120, 95, 50, 70, 40, 70, 30, 130, 576, 1800, 63, 82, 93, 102, 80, 85, 94, 160, 123, 57, 81, 275, 200, 65, 200, 54, 48, 104, 97, 160, 995, 48, 75, 30, 62, 150, 90, 40, 94, 75, 48, 68, 190, 201, 225, 80, 60, 75, 110, 85, 25, 55, 20, 30, 1113, 215, 55, 302, 122, 75, 28, 56, 65, 89, 220, 117, 49, 114, 105, 101, 66, 95, 110, 44, 105, 119, 300, 53, 140, 24, 72, 200, 13, 105, 202, 120, 150, 80, 55, 65, 185, 1318, 820, 65, 61, 80, 185, 120, 108, 130, 33, 62, 100, 27, 125, 75, 40, 96, 24, 455, 108, 48, 100, 15, 40, 85, 60, 77, 43, 119, 110, 130, 110, 144, 95, 57, 25, 76, 250, 20, 80, 37, 50, 2000, 50, 45, 205, 375, 62, 18, 22, 65, 14, 129, 40, 48, 35, 40, 80, 220, 75, 12000, 1700, 250, 85, 60, 45, 125, 60, 80, 225, 60]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tcvl745DOE4"
      },
      "source": [
        "df['price']=int_price\r\n",
        "df['price']=df['price'].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX_orr86cUW4",
        "outputId": "1ceadb4c-24b4-4a3d-a6e8-774fe792747a"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0       int64\n",
              "name            object\n",
              "category        object\n",
              "review.point     int64\n",
              "price            int64\n",
              "currency        object\n",
              "description     object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duPKo4LUSrtB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKuocvzDNP3x"
      },
      "source": [
        "features = ['category', 'price']\r\n",
        "X = df[features].copy()\r\n",
        "y = df['review.point']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXy9Kv3nLB7t"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SXGqKzUQY9t",
        "outputId": "668c3266-46cc-4cb1-d8d7-d734eeb45909"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       97\n",
              "1       97\n",
              "2       97\n",
              "3       96\n",
              "4       96\n",
              "        ..\n",
              "2242    72\n",
              "2243    71\n",
              "2244    70\n",
              "2245    70\n",
              "2246    63\n",
              "Name: review.point, Length: 2247, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zho641jTugy",
        "outputId": "2c975658-14ec-4f7a-8632-4d8f8c68d39c"
      },
      "source": [
        "s = (X_train.dtypes == 'object')\r\n",
        "object_cols = list(s[s].index)\r\n",
        "\r\n",
        "print(\"Categorical variables:\")\r\n",
        "print(object_cols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Categorical variables:\n",
            "['category']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "MNZuNsnlQddD",
        "outputId": "2882792e-aeee-4bd1-dfb1-5297e849a9db"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "\r\n",
        "# Make copy to avoid changing original data \r\n",
        "label_X_train = X_train.copy()\r\n",
        "label_X_test = X_test.copy()\r\n",
        "\r\n",
        "# Apply label encoder to each column with categorical data\r\n",
        "label_encoder = LabelEncoder()\r\n",
        "col = 'category'\r\n",
        "label_X_train[col] = label_encoder.fit_transform(X_train[col])\r\n",
        "label_X_test[col] = label_encoder.transform(X_test[col])\r\n",
        "\r\n",
        "label_X_train\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1630</th>\n",
              "      <td>4</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1843</th>\n",
              "      <td>4</td>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1516</th>\n",
              "      <td>4</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>4</td>\n",
              "      <td>325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1029</th>\n",
              "      <td>4</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1033</th>\n",
              "      <td>4</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1731</th>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>1</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>835</th>\n",
              "      <td>4</td>\n",
              "      <td>665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1653</th>\n",
              "      <td>4</td>\n",
              "      <td>153</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1685 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      category  price\n",
              "1630         4     85\n",
              "1843         4    111\n",
              "1516         4     80\n",
              "61           4    325\n",
              "1029         4    120\n",
              "...        ...    ...\n",
              "1033         4     68\n",
              "1731         1     55\n",
              "763          1     90\n",
              "835          4    665\n",
              "1653         4    153\n",
              "\n",
              "[1685 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "AKFRW9fpS8sM",
        "outputId": "6b0b8687-fab4-42f0-aada-7ff6c34f3907"
      },
      "source": [
        "df[col] = label_encoder.fit_transform(df[col])\r\n",
        "df.corr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>review.point</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.067903</td>\n",
              "      <td>-0.001294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review.point</th>\n",
              "      <td>-0.067903</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.128042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>price</th>\n",
              "      <td>-0.001294</td>\n",
              "      <td>0.128042</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              category  review.point     price\n",
              "category      1.000000     -0.067903 -0.001294\n",
              "review.point -0.067903      1.000000  0.128042\n",
              "price        -0.001294      0.128042  1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eYJWuTEYxCL",
        "outputId": "9c6f64cb-06dc-4dc8-8750-bf938f607408"
      },
      "source": [
        "label_X_train = np.array(label_X_train)\r\n",
        "label_X_test = np.array(label_X_test)\r\n",
        "y_train = np.array(y_train)\r\n",
        "y_test = np.array(y_test)\r\n",
        "\r\n",
        "label_X_train.shape[1:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxIJXK1fVU5f"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "\r\n",
        "model = keras.models.Sequential([\r\n",
        "keras.layers.Dense(30, activation=\"relu\", input_shape=label_X_train.shape[1:]),\r\n",
        "keras.layers.Dense(1)\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZWXCO7IrJc5",
        "outputId": "cf2a741d-57d2-478e-b060-ded2d4d9b8bd"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([84, 83, 85, ..., 89, 88, 84])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcWlLmOMahSj",
        "outputId": "f19c7590-7a50-4836-e332-6c0d9d78061c"
      },
      "source": [
        "model.compile(loss=\"mean_squared_error\", optimizer=\"Adam\")\r\n",
        "history = model.fit(label_X_train, y_train, epochs=30,\r\n",
        "validation_data=(label_X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "53/53 [==============================] - 1s 4ms/step - loss: 7729.8898 - val_loss: 22230.4551\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7408.0971 - val_loss: 18988.3301\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8555.6942 - val_loss: 14017.2422\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7413.2972 - val_loss: 7282.2725\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 8066.9903 - val_loss: 11560.3730\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6391.9537 - val_loss: 6990.5996\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7014.5820 - val_loss: 14211.0479\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6497.8141 - val_loss: 11433.6953\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 6139.7210 - val_loss: 11857.7578\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7625.2188 - val_loss: 34439.3398\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 7088.0516 - val_loss: 26269.1738\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5898.9390 - val_loss: 8748.7500\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5627.5011 - val_loss: 5574.7881\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5273.1434 - val_loss: 7989.4326\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 5390.7214 - val_loss: 9838.0195\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5319.4980 - val_loss: 5020.0996\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4972.3129 - val_loss: 14609.1953\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4680.2018 - val_loss: 5568.8350\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4981.6386 - val_loss: 4949.6440\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4547.6832 - val_loss: 4507.4873\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4212.8055 - val_loss: 4291.8096\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5583.1477 - val_loss: 4418.6860\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4453.3139 - val_loss: 8822.5498\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5452.2009 - val_loss: 4174.1558\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3740.9428 - val_loss: 3752.4351\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3722.3860 - val_loss: 4567.5918\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 4473.3869 - val_loss: 4537.9126\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3485.3190 - val_loss: 6458.2563\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 3296.5791 - val_loss: 8908.2354\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 5095.0125 - val_loss: 11402.5352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbbnAZPTNX4o",
        "outputId": "c653cf03-1b2e-468e-f0fa-27e292d20110"
      },
      "source": [
        "mse_test = model.evaluate(label_X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 922us/step - loss: 11402.5352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3N0Li6uOFnJ"
      },
      "source": [
        "X_new = label_X_test[:8] # pretend these are new instances\r\n",
        "y_pred = model.predict(X_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69LrGrp6OS0r",
        "outputId": "bdf61e7e-a590-402b-b2f8-3f73cfc4abc6"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[86.66673],\n",
              "       [86.66673],\n",
              "       [86.66673],\n",
              "       [86.66673],\n",
              "       [86.66673],\n",
              "       [86.66673],\n",
              "       [86.66673],\n",
              "       [86.66673]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHUaA1dvOV52",
        "outputId": "c2704963-42a0-4251-bd49-cb23d01c49f1"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([85, 86, 84, 81, 84, 84, 82, 85, 89, 85, 93, 82, 88, 80, 90, 86, 88,\n",
              "       83, 87, 88, 86, 86, 88, 91, 87, 91, 89, 93, 80, 90, 86, 80, 87, 83,\n",
              "       90, 88, 88, 88, 90, 89, 80, 96, 94, 90, 85, 90, 89, 93, 79, 83, 84,\n",
              "       86, 84, 79, 85, 80, 86, 84, 87, 88, 89, 84, 89, 90, 85, 88, 83, 88,\n",
              "       86, 86, 88, 91, 90, 91, 87, 94, 82, 88, 88, 85, 85, 93, 84, 90, 85,\n",
              "       93, 81, 89, 80, 83, 90, 82, 86, 88, 89, 90, 89, 89, 93, 93, 89, 90,\n",
              "       87, 80, 87, 83, 88, 91, 87, 80, 90, 94, 88, 87, 81, 87, 84, 85, 88,\n",
              "       92, 90, 94, 85, 86, 77, 92, 80, 83, 86, 87, 75, 85, 93, 89, 83, 95,\n",
              "       90, 84, 86, 74, 86, 88, 78, 87, 85, 86, 89, 92, 91, 84, 90, 86, 90,\n",
              "       90, 92, 94, 83, 85, 82, 90, 88, 85, 84, 92, 83, 86, 81, 83, 88, 84,\n",
              "       83, 86, 90, 86, 86, 89, 88, 92, 92, 84, 85, 87, 88, 89, 87, 82, 85,\n",
              "       95, 90, 82, 89, 81, 81, 90, 87, 86, 73, 85, 88, 84, 93, 92, 84, 81,\n",
              "       85, 89, 90, 79, 83, 80, 90, 86, 91, 85, 79, 90, 89, 83, 84, 94, 90,\n",
              "       88, 81, 87, 87, 89, 89, 90, 87, 79, 93, 86, 88, 86, 90, 86, 84, 95,\n",
              "       92, 82, 92, 88, 85, 86, 88, 83, 84, 85, 87, 94, 83, 92, 89, 79, 85,\n",
              "       96, 92, 92, 79, 88, 95, 90, 87, 90, 78, 86, 93, 87, 90, 82, 90, 88,\n",
              "       85, 90, 91, 88, 88, 89, 87, 70, 85, 92, 95, 87, 90, 90, 90, 87, 85,\n",
              "       80, 89, 80, 87, 91, 80, 83, 86, 86, 93, 89, 90, 87, 89, 90, 90, 90,\n",
              "       85, 87, 77, 96, 74, 84, 82, 95, 88, 83, 89, 79, 82, 86, 86, 93, 94,\n",
              "       92, 89, 83, 87, 86, 90, 83, 91, 85, 89, 83, 84, 89, 87, 90, 87, 83,\n",
              "       89, 87, 81, 82, 87, 91, 84, 86, 88, 83, 77, 89, 87, 86, 95, 92, 89,\n",
              "       85, 84, 93, 91, 88, 82, 83, 85, 90, 89, 83, 86, 92, 88, 86, 87, 87,\n",
              "       85, 80, 84, 85, 92, 80, 89, 88, 81, 91, 85, 84, 94, 89, 89, 91, 88,\n",
              "       92, 92, 86, 82, 89, 84, 86, 85, 81, 91, 89, 84, 87, 88, 90, 84, 95,\n",
              "       84, 85, 85, 90, 90, 83, 90, 91, 85, 84, 90, 85, 90, 85, 91, 80, 91,\n",
              "       83, 86, 91, 80, 90, 85, 84, 84, 81, 85, 86, 85, 88, 78, 82, 82, 93,\n",
              "       86, 89, 85, 85, 89, 96, 91, 90, 82, 94, 87, 90, 88, 92, 88, 89, 92,\n",
              "       87, 87, 73, 84, 89, 88, 90, 90, 85, 86, 91, 88, 86, 86, 90, 91, 89,\n",
              "       85, 86, 81, 84, 82, 80, 82, 85, 93, 92, 86, 95, 90, 88, 93, 85, 86,\n",
              "       86, 97, 87, 85, 84, 86, 91, 82, 87, 72, 93, 89, 88, 86, 88, 86, 88,\n",
              "       80, 83, 89, 88, 85, 87, 91, 92, 88, 89, 88, 88, 89, 82, 91, 89, 86,\n",
              "       85, 88, 82, 93, 84, 92, 81, 85, 89, 84, 86, 87, 89, 89, 79, 83, 85,\n",
              "       72, 78, 87, 87, 89, 93, 84, 95, 85, 91, 81, 85, 82, 84, 89, 87, 90,\n",
              "       87])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQQ6XIVwRxxW",
        "outputId": "14730c40-5c19-48ab-b544-0b4390caaa48"
      },
      "source": [
        "from xgboost import XGBRegressor\r\n",
        "\r\n",
        "my_model = XGBRegressor()\r\n",
        "my_model.fit(label_X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[15:05:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
              "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
              "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
              "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "             silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZdAlBZ-SEQI",
        "outputId": "ffaf693a-19f0-4847-c8e1-fdc50dfa1ba2"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\r\n",
        "\r\n",
        "predictions = my_model.predict(label_X_test)\r\n",
        "print(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 2.954697972090643\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a6Yn2RLQZaR"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW0gNAEbSYG-",
        "outputId": "b9f2d73e-eb31-4f7c-f91c-8096e3cbd438"
      },
      "source": [
        "X_new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  4, 160],\n",
              "       [  4,  70],\n",
              "       [  4,  80],\n",
              "       [  4,  52],\n",
              "       [  4,  75],\n",
              "       [  4, 108],\n",
              "       [  4,  55],\n",
              "       [  4,  53]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnqEATdsT99e",
        "outputId": "d2778e23-6b35-4db7-8bd9-e61c21db8ff6"
      },
      "source": [
        "my_model.predict(X_new)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([86.94333 , 85.41621 , 85.385025, 85.16181 , 85.1069  , 86.08907 ,\n",
              "       85.16181 , 85.16181 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8yxutyIT_C-",
        "outputId": "3da7c247-ba61-4ff3-b398-b61c68795d72"
      },
      "source": [
        "y_test[:8]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([85, 86, 84, 81, 84, 84, 82, 85])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    }
  ]
}